Cuda is availiable... Using 2 devices
CONFIG INFO:  {'d_model': 512, 'FF_innerlayer_dim': 1024, 'key_vector_dim': 256, 'value_vector_dim': 256, 'emb_dimension': 512, 'encoder_layer_num': 6, 'decoder_layer_num': 6, 'attention_num_heads': 8, 'batch_size': 32, 'epochs': 40}
Load dataset ...
Preprocess ...
English corpus: 32968 num of words and 25000 num of sentences
Deutsch corpus: 56117 num of words and 25000 num of sentences
English max length: 100 
Deutsch max length: 100
Epoch[1/40] Step[100/781] loss= 4.116716
Epoch[1/40] Step[200/781] loss= 2.171080
Epoch[1/40] Step[300/781] loss= 2.214074
Epoch[1/40] Step[400/781] loss= 1.771636
Epoch[1/40] Step[500/781] loss= 1.786065
Epoch[1/40] Step[600/781] loss= 1.729574
Epoch[1/40] Step[700/781] loss= 1.551756
 > 1 Epoch Summary: Total avg loss =  2.131544
Epoch[2/40] Step[100/781] loss= 1.627326
Epoch[2/40] Step[200/781] loss= 1.451536
Epoch[2/40] Step[300/781] loss= 1.639416
Epoch[2/40] Step[400/781] loss= 1.371567
Epoch[2/40] Step[500/781] loss= 1.455841
Epoch[2/40] Step[600/781] loss= 1.408965
Epoch[2/40] Step[700/781] loss= 1.283572
 > 2 Epoch Summary: Total avg loss =  1.448866
Epoch[3/40] Step[100/781] loss= 1.345182
Epoch[3/40] Step[200/781] loss= 1.225864
Epoch[3/40] Step[300/781] loss= 1.404837
Epoch[3/40] Step[400/781] loss= 1.195536
Epoch[3/40] Step[500/781] loss= 1.318980
Epoch[3/40] Step[600/781] loss= 1.281468
Epoch[3/40] Step[700/781] loss= 1.183215
 > 3 Epoch Summary: Total avg loss =  1.274722
Epoch[4/40] Step[100/781] loss= 1.230768
Epoch[4/40] Step[200/781] loss= 1.130972
Epoch[4/40] Step[300/781] loss= 1.303156
Epoch[4/40] Step[400/781] loss= 1.103865
Epoch[4/40] Step[500/781] loss= 1.243117
Epoch[4/40] Step[600/781] loss= 1.199030
Epoch[4/40] Step[700/781] loss= 1.109517
 > 4 Epoch Summary: Total avg loss =  1.186516
Epoch[5/40] Step[100/781] loss= 1.154192
Epoch[5/40] Step[200/781] loss= 1.063189
Epoch[5/40] Step[300/781] loss= 1.228910
Epoch[5/40] Step[400/781] loss= 1.038584
Epoch[5/40] Step[500/781] loss= 1.190274
Epoch[5/40] Step[600/781] loss= 1.138039
Epoch[5/40] Step[700/781] loss= 1.052236
 > 5 Epoch Summary: Total avg loss =  1.122820
Epoch[6/40] Step[100/781] loss= 1.091590
Epoch[6/40] Step[200/781] loss= 1.007290
Epoch[6/40] Step[300/781] loss= 1.168353
Epoch[6/40] Step[400/781] loss= 0.984379
Epoch[6/40] Step[500/781] loss= 1.144983
Epoch[6/40] Step[600/781] loss= 1.085970
Epoch[6/40] Step[700/781] loss= 1.003707
 > 6 Epoch Summary: Total avg loss =  1.069494
Epoch[7/40] Step[100/781] loss= 1.037549
Epoch[7/40] Step[200/781] loss= 0.959402
Epoch[7/40] Step[300/781] loss= 1.114930
Epoch[7/40] Step[400/781] loss= 0.937824
Epoch[7/40] Step[500/781] loss= 1.105947
Epoch[7/40] Step[600/781] loss= 1.040426
Epoch[7/40] Step[700/781] loss= 0.961345
 > 7 Epoch Summary: Total avg loss =  1.023233
Epoch[8/40] Step[100/781] loss= 0.989795
Epoch[8/40] Step[200/781] loss= 0.917728
Epoch[8/40] Step[300/781] loss= 1.067776
Epoch[8/40] Step[400/781] loss= 0.897921
Epoch[8/40] Step[500/781] loss= 1.070415
Epoch[8/40] Step[600/781] loss= 1.000106
Epoch[8/40] Step[700/781] loss= 0.924572
 > 8 Epoch Summary: Total avg loss =  0.982442
Epoch[9/40] Step[100/781] loss= 0.947325
Epoch[9/40] Step[200/781] loss= 0.881276
Epoch[9/40] Step[300/781] loss= 1.025369
Epoch[9/40] Step[400/781] loss= 0.862687
Epoch[9/40] Step[500/781] loss= 1.038970
Epoch[9/40] Step[600/781] loss= 0.963731
Epoch[9/40] Step[700/781] loss= 0.891461
 > 9 Epoch Summary: Total avg loss =  0.946079
Epoch[10/40] Step[100/781] loss= 0.908847
Epoch[10/40] Step[200/781] loss= 0.848384
Epoch[10/40] Step[300/781] loss= 0.986911
Epoch[10/40] Step[400/781] loss= 0.830872
Epoch[10/40] Step[500/781] loss= 1.009776
Epoch[10/40] Step[600/781] loss= 0.930579
Epoch[10/40] Step[700/781] loss= 0.861532
 > 10 Epoch Summary: Total avg loss =  0.913003
Epoch[11/40] Step[100/781] loss= 0.873734
Epoch[11/40] Step[200/781] loss= 0.818280
Epoch[11/40] Step[300/781] loss= 0.951773
Epoch[11/40] Step[400/781] loss= 0.801583
Epoch[11/40] Step[500/781] loss= 0.982616
Epoch[11/40] Step[600/781] loss= 0.900063
Epoch[11/40] Step[700/781] loss= 0.833976
 > 11 Epoch Summary: Total avg loss =  0.882605
Epoch[12/40] Step[100/781] loss= 0.841566
Epoch[12/40] Step[200/781] loss= 0.790560
Epoch[12/40] Step[300/781] loss= 0.919570
Epoch[12/40] Step[400/781] loss= 0.774609
Epoch[12/40] Step[500/781] loss= 0.957366
Epoch[12/40] Step[600/781] loss= 0.872004
Epoch[12/40] Step[700/781] loss= 0.808443
 > 12 Epoch Summary: Total avg loss =  0.854595
Epoch[13/40] Step[100/781] loss= 0.812067
Epoch[13/40] Step[200/781] loss= 0.764913
Epoch[13/40] Step[300/781] loss= 0.889825
Epoch[13/40] Step[400/781] loss= 0.749676
Epoch[13/40] Step[500/781] loss= 0.933425
Epoch[13/40] Step[600/781] loss= 0.846033
Epoch[13/40] Step[700/781] loss= 0.784746
 > 13 Epoch Summary: Total avg loss =  0.828624
Epoch[14/40] Step[100/781] loss= 0.784868
Epoch[14/40] Step[200/781] loss= 0.741116
Epoch[14/40] Step[300/781] loss= 0.862327
Epoch[14/40] Step[400/781] loss= 0.726583
Epoch[14/40] Step[500/781] loss= 0.911050
Epoch[14/40] Step[600/781] loss= 0.822072
Epoch[14/40] Step[700/781] loss= 0.762674
 > 14 Epoch Summary: Total avg loss =  0.804582
Epoch[15/40] Step[100/781] loss= 0.759967
Epoch[15/40] Step[200/781] loss= 0.719082
Epoch[15/40] Step[300/781] loss= 0.836970
Epoch[15/40] Step[400/781] loss= 0.705163
Epoch[15/40] Step[500/781] loss= 0.890145
Epoch[15/40] Step[600/781] loss= 0.799902
Epoch[15/40] Step[700/781] loss= 0.742285
 > 15 Epoch Summary: Total avg loss =  0.782364
Epoch[16/40] Step[100/781] loss= 0.737140
Epoch[16/40] Step[200/781] loss= 0.698558
Epoch[16/40] Step[300/781] loss= 0.813525
Epoch[16/40] Step[400/781] loss= 0.685262
Epoch[16/40] Step[500/781] loss= 0.870460
Epoch[16/40] Step[600/781] loss= 0.779299
Epoch[16/40] Step[700/781] loss= 0.723171
 > 16 Epoch Summary: Total avg loss =  0.761730
Epoch[17/40] Step[100/781] loss= 0.716039
Epoch[17/40] Step[200/781] loss= 0.679471
Epoch[17/40] Step[300/781] loss= 0.791740
Epoch[17/40] Step[400/781] loss= 0.666700
Epoch[17/40] Step[500/781] loss= 0.851957
Epoch[17/40] Step[600/781] loss= 0.760169
Epoch[17/40] Step[700/781] loss= 0.705407
 > 17 Epoch Summary: Total avg loss =  0.742530
Epoch[18/40] Step[100/781] loss= 0.696360
Epoch[18/40] Step[200/781] loss= 0.661505
Epoch[18/40] Step[300/781] loss= 0.771330
Epoch[18/40] Step[400/781] loss= 0.649289
Epoch[18/40] Step[500/781] loss= 0.834400
Epoch[18/40] Step[600/781] loss= 0.742183
Epoch[18/40] Step[700/781] loss= 0.688691
 > 18 Epoch Summary: Total avg loss =  0.724494
Epoch[19/40] Step[100/781] loss= 0.677885
Epoch[19/40] Step[200/781] loss= 0.644662
Epoch[19/40] Step[300/781] loss= 0.752054
Epoch[19/40] Step[400/781] loss= 0.633002
Epoch[19/40] Step[500/781] loss= 0.817504
Epoch[19/40] Step[600/781] loss= 0.725317
Epoch[19/40] Step[700/781] loss= 0.672887
 > 19 Epoch Summary: Total avg loss =  0.707492
Epoch[20/40] Step[100/781] loss= 0.660390
Epoch[20/40] Step[200/781] loss= 0.628717
Epoch[20/40] Step[300/781] loss= 0.733820
Epoch[20/40] Step[400/781] loss= 0.617588
Epoch[20/40] Step[500/781] loss= 0.801479
Epoch[20/40] Step[600/781] loss= 0.709391
Epoch[20/40] Step[700/781] loss= 0.658017
 > 20 Epoch Summary: Total avg loss =  0.691405
Epoch[21/40] Step[100/781] loss= 0.643781
Epoch[21/40] Step[200/781] loss= 0.613600
Epoch[21/40] Step[300/781] loss= 0.716553
Epoch[21/40] Step[400/781] loss= 0.603028
Epoch[21/40] Step[500/781] loss= 0.786077
Epoch[21/40] Step[600/781] loss= 0.694343
Epoch[21/40] Step[700/781] loss= 0.643955
 > 21 Epoch Summary: Total avg loss =  0.676147
Epoch[22/40] Step[100/781] loss= 0.628013
Epoch[22/40] Step[200/781] loss= 0.599286
Epoch[22/40] Step[300/781] loss= 0.700151
Epoch[22/40] Step[400/781] loss= 0.589235
Epoch[22/40] Step[500/781] loss= 0.771305
Epoch[22/40] Step[600/781] loss= 0.680087
Epoch[22/40] Step[700/781] loss= 0.630754
 > 22 Epoch Summary: Total avg loss =  0.661679
Epoch[23/40] Step[100/781] loss= 0.612984
Epoch[23/40] Step[200/781] loss= 0.585657
Epoch[23/40] Step[300/781] loss= 0.684613
Epoch[23/40] Step[400/781] loss= 0.576148
Epoch[23/40] Step[500/781] loss= 0.757263
Epoch[23/40] Step[600/781] loss= 0.666622
Epoch[23/40] Step[700/781] loss= 0.618163
 > 23 Epoch Summary: Total avg loss =  0.647921
Epoch[24/40] Step[100/781] loss= 0.598622
Epoch[24/40] Step[200/781] loss= 0.572740
Epoch[24/40] Step[300/781] loss= 0.669579
Epoch[24/40] Step[400/781] loss= 0.563743
Epoch[24/40] Step[500/781] loss= 0.743442
Epoch[24/40] Step[600/781] loss= 0.653779
Epoch[24/40] Step[700/781] loss= 0.606130
 > 24 Epoch Summary: Total avg loss =  0.634734
Epoch[25/40] Step[100/781] loss= 0.584826
Epoch[25/40] Step[200/781] loss= 0.560466
Epoch[25/40] Step[300/781] loss= 0.655366
Epoch[25/40] Step[400/781] loss= 0.551942
Epoch[25/40] Step[500/781] loss= 0.730430
Epoch[25/40] Step[600/781] loss= 0.641494
Epoch[25/40] Step[700/781] loss= 0.594970
 > 25 Epoch Summary: Total avg loss =  0.622235
Epoch[26/40] Step[100/781] loss= 0.571612
Epoch[26/40] Step[200/781] loss= 0.548628
Epoch[26/40] Step[300/781] loss= 0.641515
Epoch[26/40] Step[400/781] loss= 0.540686
Epoch[26/40] Step[500/781] loss= 0.717651
Epoch[26/40] Step[600/781] loss= 0.629793
Epoch[26/40] Step[700/781] loss= 0.584199
 > 26 Epoch Summary: Total avg loss =  0.610167
Epoch[27/40] Step[100/781] loss= 0.558826
Epoch[27/40] Step[200/781] loss= 0.537174
Epoch[27/40] Step[300/781] loss= 0.628255
Epoch[27/40] Step[400/781] loss= 0.529856
Epoch[27/40] Step[500/781] loss= 0.705285
Epoch[27/40] Step[600/781] loss= 0.618485
Epoch[27/40] Step[700/781] loss= 0.573975
 > 27 Epoch Summary: Total avg loss =  0.598541
Epoch[28/40] Step[100/781] loss= 0.546678
Epoch[28/40] Step[200/781] loss= 0.526224
Epoch[28/40] Step[300/781] loss= 0.615509
Epoch[28/40] Step[400/781] loss= 0.519596
Epoch[28/40] Step[500/781] loss= 0.693362
Epoch[28/40] Step[600/781] loss= 0.607745
Epoch[28/40] Step[700/781] loss= 0.564231
 > 28 Epoch Summary: Total avg loss =  0.587461
Epoch[29/40] Step[100/781] loss= 0.534857
Epoch[29/40] Step[200/781] loss= 0.515715
Epoch[29/40] Step[300/781] loss= 0.603303
Epoch[29/40] Step[400/781] loss= 0.509737
Epoch[29/40] Step[500/781] loss= 0.681918
Epoch[29/40] Step[600/781] loss= 0.597449
Epoch[29/40] Step[700/781] loss= 0.555048
 > 29 Epoch Summary: Total avg loss =  0.576821
Epoch[30/40] Step[100/781] loss= 0.523651
Epoch[30/40] Step[200/781] loss= 0.505630
Epoch[30/40] Step[300/781] loss= 0.591611
Epoch[30/40] Step[400/781] loss= 0.500321
Epoch[30/40] Step[500/781] loss= 0.671016
Epoch[30/40] Step[600/781] loss= 0.587671
Epoch[30/40] Step[700/781] loss= 0.546224
 > 30 Epoch Summary: Total avg loss =  0.566658
Epoch[31/40] Step[100/781] loss= 0.512618
Epoch[31/40] Step[200/781] loss= 0.495714
Epoch[31/40] Step[300/781] loss= 0.580205
Epoch[31/40] Step[400/781] loss= 0.491128
Epoch[31/40] Step[500/781] loss= 0.660094
Epoch[31/40] Step[600/781] loss= 0.577974
Epoch[31/40] Step[700/781] loss= 0.537535
 > 31 Epoch Summary: Total avg loss =  0.556635
Epoch[32/40] Step[100/781] loss= 0.502129
Epoch[32/40] Step[200/781] loss= 0.486233
Epoch[32/40] Step[300/781] loss= 0.569227
Epoch[32/40] Step[400/781] loss= 0.482343
Epoch[32/40] Step[500/781] loss= 0.649786
Epoch[32/40] Step[600/781] loss= 0.568879
Epoch[32/40] Step[700/781] loss= 0.529321
 > 32 Epoch Summary: Total avg loss =  0.547140
Epoch[33/40] Step[100/781] loss= 0.491988
Epoch[33/40] Step[200/781] loss= 0.476951
Epoch[33/40] Step[300/781] loss= 0.558661
Epoch[33/40] Step[400/781] loss= 0.473784
Epoch[33/40] Step[500/781] loss= 0.639704
Epoch[33/40] Step[600/781] loss= 0.559918
Epoch[33/40] Step[700/781] loss= 0.521511
 > 33 Epoch Summary: Total avg loss =  0.537886
Epoch[34/40] Step[100/781] loss= 0.482158
Epoch[34/40] Step[200/781] loss= 0.468137
Epoch[34/40] Step[300/781] loss= 0.548434
Epoch[34/40] Step[400/781] loss= 0.465583
Epoch[34/40] Step[500/781] loss= 0.629983
Epoch[34/40] Step[600/781] loss= 0.551370
Epoch[34/40] Step[700/781] loss= 0.513719
 > 34 Epoch Summary: Total avg loss =  0.528969
Epoch[35/40] Step[100/781] loss= 0.472530
Epoch[35/40] Step[200/781] loss= 0.459443
Epoch[35/40] Step[300/781] loss= 0.538490
Epoch[35/40] Step[400/781] loss= 0.457641
Epoch[35/40] Step[500/781] loss= 0.620482
Epoch[35/40] Step[600/781] loss= 0.543072
Epoch[35/40] Step[700/781] loss= 0.506281
 > 35 Epoch Summary: Total avg loss =  0.520304
Epoch[36/40] Step[100/781] loss= 0.463383
Epoch[36/40] Step[200/781] loss= 0.451051
Epoch[36/40] Step[300/781] loss= 0.528959
Epoch[36/40] Step[400/781] loss= 0.449887
Epoch[36/40] Step[500/781] loss= 0.611450
Epoch[36/40] Step[600/781] loss= 0.535091
Epoch[36/40] Step[700/781] loss= 0.499270
 > 36 Epoch Summary: Total avg loss =  0.511990
Epoch[37/40] Step[100/781] loss= 0.454358
Epoch[37/40] Step[200/781] loss= 0.442870
Epoch[37/40] Step[300/781] loss= 0.519608
Epoch[37/40] Step[400/781] loss= 0.442378
Epoch[37/40] Step[500/781] loss= 0.602314
Epoch[37/40] Step[600/781] loss= 0.527230
Epoch[37/40] Step[700/781] loss= 0.492143
 > 37 Epoch Summary: Total avg loss =  0.503792
Epoch[38/40] Step[100/781] loss= 0.445740
Epoch[38/40] Step[200/781] loss= 0.435083
Epoch[38/40] Step[300/781] loss= 0.510591
Epoch[38/40] Step[400/781] loss= 0.435199
Epoch[38/40] Step[500/781] loss= 0.593761
Epoch[38/40] Step[600/781] loss= 0.520029
Epoch[38/40] Step[700/781] loss= 0.485592
 > 38 Epoch Summary: Total avg loss =  0.496066
Epoch[39/40] Step[100/781] loss= 0.437442
Epoch[39/40] Step[200/781] loss= 0.427401
Epoch[39/40] Step[300/781] loss= 0.501817
Epoch[39/40] Step[400/781] loss= 0.428208
Epoch[39/40] Step[500/781] loss= 0.585305
Epoch[39/40] Step[600/781] loss= 0.512762
Epoch[39/40] Step[700/781] loss= 0.479193
 > 39 Epoch Summary: Total avg loss =  0.488461
Epoch[40/40] Step[100/781] loss= 0.429339
Epoch[40/40] Step[200/781] loss= 0.420082
Epoch[40/40] Step[300/781] loss= 0.493438
Epoch[40/40] Step[400/781] loss= 0.421302
Epoch[40/40] Step[500/781] loss= 0.577144
Epoch[40/40] Step[600/781] loss= 0.505825
Epoch[40/40] Step[700/781] loss= 0.473034
 > 40 Epoch Summary: Total avg loss =  0.481116
Load Test dataset ...
English corpus: 4006 num of words and 1000 num of sentences
Deutsch corpus: 5398 num of words and 1000 num of sentences

--------------<Sample Result>------------------

(I) it is time to define the winners'
(T) nun sind nur noch die sieger zu definieren'
(P) nun sind nur noch die kontakt zu definieren'

...Attention Graphs have saved. Check [results] directory
