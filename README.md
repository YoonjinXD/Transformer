# Transformer

Simple Implementation of Transformer which appeared in '[Attention is all you need](https://arxiv.org/abs/1706.03762)'.<br>
To test the model
1. clone this repository
2. download required packages
3. run 'download.sh' scipt file to download datasets
4. run 'python transformer.py test'

### Sample Result Screenshot
#### (1) Sample sentence
<img src='sample_result.png'>
(I) = Input sentence
(T) = Traget sentence
(P) = Predict sentence

#### (2) Sample attention graph
<img src='results/dec_combo_attn.png'>
