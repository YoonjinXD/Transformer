# Transformer

Simple Implementation of Transformer which appeared in '[Attention is all you need](https://arxiv.org/abs/1706.03762)'.<br>
To test the model
1. clone this repository
2. download required packages
3. run 'download.sh' scipt file to download datasets
4. run 'python transformer.py test'

### Sample Result Screenshot
* <p>Dataset: [Stanford's Neural Machine Translation Project](https://nlp.stanford.edu/projects/nmt/). English to Deutsch(Germany)</p>

* <p>Sample Translation sentence
<img src='sample_result.png'>
(I) = Input sentence <br> 
(T) = Traget sentence <br> 
(P) = Predict sentence <br></p>

* <p>Sample Attention graph
<img src='results/dec_combo_attn.png'></p>
